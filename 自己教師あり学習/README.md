# Self-Supervised Learning（自己教師あり学習）

このフォルダには、Transformer/BERTベースの自己教師あり学習モデルが含まれています。

## ファイル構成

- `task/`: タスク関連コード
  - `dataset.py`: データセットクラス（Task4Dataset）
  - `model.py`: BERTモデル（Task4BERT）
  - `train.py`: 学習スクリプト
- `train_colab.ipynb`: Google Colab用の学習ノートブック
- `output/`: 学習結果（モデル、損失カーブなど）
- `utils/`: ユーティリティスクリプト
  - `debug_attention.py`: アテンションウェイトのデバッグ

## 使用方法

1. Colabで学習:
   - `ssl/train_colab.ipynb` をGoogle Colabで開く
   - 必要なファイルをアップロード
   - セルを順番に実行

2. 評価:
   - ルートの `eval.py` を使用（ベースラインと共通）

## タスク4: マスク予測 + 正則化項

- **マスク予測**: 15%の区間をマスクし、元の値を予測
- **正則化項**: ランキング損失を使用して、ノイズ区間のアテンション < 正常区間のアテンション になるように学習

## データの前処理

- スケーリング: `2.5e24`
- ログ変換: `np.log(x.clamp(min=1e-30))`
- 正規化: ログ変換後のデータを正規化（mean=0, std=1）
- 構造化ノイズ: 実験データに近づけるため、全体的な構造化ノイズを付与
- 区間ノイズ: 30区間のうち1区間にノイズを付与（ノイズ検知の対象）

## 詳細

詳細な設計については `docs/ssl/task_design.md` を参照してください。

