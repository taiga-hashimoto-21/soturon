# ランキング損失の詳細説明

## 現在の予測方法

### 1. 予測の仕組み
```python
# 30区間それぞれのアテンション値を計算
interval_attention = [attn_0, attn_1, attn_2, ..., attn_29]  # (30,)

# 最もアテンションが低い区間を予測
predicted_noise_interval = argmin(interval_attention)  # 最小値のインデックス
```

### 2. 現在の損失関数
```python
# ノイズ区間のアテンションを0に近づける
noise_interval_attention = interval_attention[noise_interval]  # ノイズ区間のアテンション
target = 0.0  # 目標は0
loss = MSE(noise_interval_attention, target)
```

### 3. 問題点
- ノイズ区間のアテンションを0に近づけても、正常区間のどれかが偶然それより低くなる可能性がある
- 例: ノイズ区間のアテンション = 0.000125, 正常区間0のアテンション = 0.000024
  - 正常区間0の方が低いので、予測は0になる
  - しかし正解はノイズ区間なので、予測が外れる

## ランキング損失とは？

### 基本的な考え方
「ノイズ区間のアテンション < 正常区間の最小アテンション」を保証する

### 具体的な実装

```python
# 各サンプルで
for i in range(B):
    noise_idx = noise_intervals[i]  # ノイズ区間のインデックス
    noise_attn = interval_attention[i, noise_idx]  # ノイズ区間のアテンション
    
    # 正常区間のインデックスを取得
    normal_indices = [j for j in range(30) if j != noise_idx]
    normal_attns = interval_attention[i, normal_indices]  # 正常区間のアテンション
    normal_min_attn = normal_attns.min()  # 正常区間の最小アテンション
    
    # ランキング損失: ノイズ区間のアテンション < 正常区間の最小アテンション
    margin = 0.01  # マージン（余裕を持たせる）
    ranking_loss += max(0, noise_attn - normal_min_attn + margin)
    # max(0, ...) は、差が負（ノイズ < 正常）の場合は0、正（ノイズ > 正常）の場合はペナルティ

ranking_loss = ranking_loss / B  # バッチ平均
```

### 損失関数の意味

1. **noise_attn - normal_min_attn + margin**
   - ノイズ区間のアテンション - 正常区間の最小アテンション + マージン
   - この値が正（ノイズ > 正常）の場合、ペナルティが発生

2. **max(0, ...)**
   - 差が負（ノイズ < 正常）の場合は0（ペナルティなし）
   - 差が正（ノイズ > 正常）の場合はペナルティ（差 + マージン）

3. **margin（マージン）**
   - 余裕を持たせるための値（例: 0.01）
   - ノイズ区間のアテンションが正常区間より少し低いだけでは不十分
   - マージン分だけ低くする必要がある

### 例

**現在の状況（予測が外れたサンプル）:**
```
ノイズ区間10のアテンション: 0.000125
正常区間0のアテンション: 0.000024  ← 最小
差: 0.000125 - 0.000024 = 0.000101（正）
→ ランキング損失 = 0.000101 + 0.01 = 0.010101
```

**理想的な状況:**
```
ノイズ区間10のアテンション: 0.000010
正常区間0のアテンション: 0.000024  ← 最小
差: 0.000010 - 0.000024 = -0.000014（負）
→ ランキング損失 = max(0, -0.000014 + 0.01) = max(0, 0.009986) = 0.009986
→ または、マージンが十分大きければ max(0, -0.000014 + 0.01) = 0（ペナルティなし）
```

## ランキング損失を追加する効果

1. **確実性の向上**
   - ノイズ区間のアテンションが正常区間より低くなることを保証
   - 予測が外れる可能性を大幅に減らす

2. **学習の安定化**
   - 正常区間のアテンションが均一になる
   - 偶然低い値が現れるのを防ぐ

3. **精度の向上**
   - 現在の精度: 21.34%
   - ランキング損失追加後: 50%以上を期待

## 実装時の注意点

1. **マージンの設定**
   - 小さすぎると効果が薄い
   - 大きすぎると学習が難しくなる
   - 推奨: 0.01程度

2. **損失の重み**
   - `lambda_ranking`を追加
   - 推奨: 10.0-50.0程度

3. **他の損失とのバランス**
   - マスク予測損失、正則化損失、復元損失とのバランスを取る
   - 総損失に適切に組み込む

