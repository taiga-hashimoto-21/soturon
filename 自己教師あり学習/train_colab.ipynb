{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ–¹æ³•\n",
        "\n",
        "## Google Driveã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
        "\n",
        "Google Driveã«`soturon`ãƒ•ã‚©ãƒ«ãƒ€ã‚’ãã®ã¾ã¾ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚\n",
        "\n",
        "**ãƒ•ã‚©ãƒ«ãƒ€æ§‹é€ **:\n",
        "```\n",
        "Google Drive/\n",
        "â””â”€â”€ MyDrive/\n",
        "    â””â”€â”€ soturon/\n",
        "        â”œâ”€â”€ è‡ªå·±æ•™å¸«ã‚ã‚Šå­¦ç¿’/\n",
        "        â”‚   â””â”€â”€ task/\n",
        "        â”‚       â”œâ”€â”€ __init__.py\n",
        "        â”‚       â”œâ”€â”€ dataset.py\n",
        "        â”‚       â”œâ”€â”€ model.py\n",
        "        â”‚       â””â”€â”€ train.py\n",
        "        â”œâ”€â”€ ãƒã‚¤ã‚ºã®ä»˜ä¸(å…±é€š)/\n",
        "        â”‚   â”œâ”€â”€ __init__.py\n",
        "        â”‚   â”œâ”€â”€ add_noise.py\n",
        "        â”‚   â”œâ”€â”€ power_supply_noise.py\n",
        "        â”‚   â”œâ”€â”€ interference_noise.py\n",
        "        â”‚   â””â”€â”€ clock_leakage_noise.py\n",
        "        â”œâ”€â”€ eval.py\n",
        "        â””â”€â”€ data_lowF_noise.pickle\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Google Driveã‚’ãƒã‚¦ãƒ³ãƒˆ\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ã‚¿ã‚¹ã‚¯4: ãƒã‚¹ã‚¯äºˆæ¸¬ + æ­£å‰‡åŒ–é …\n",
        "\n",
        "è‡ªå·±æ•™å¸«ã‚ã‚Šå­¦ç¿’ã«ã‚ˆã‚‹ãƒã‚¤ã‚ºæ¤œå‡º\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. ç’°å¢ƒè¨­å®š\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ã“ã®ã‚»ãƒ«ã¯ä¸è¦ï¼ˆã‚»ãƒ«1ã§ãƒã‚¦ãƒ³ãƒˆæ¸ˆã¿ï¼‰\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install scikit-learn matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨­å®š\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Google Driveã«soturonãƒ•ã‚©ãƒ«ãƒ€ã‚’ãã®ã¾ã¾ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
        "project_root = '/content/drive/MyDrive/soturon'  # soturonãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ«ãƒ¼ãƒˆ\n",
        "ssl_folder = f'{project_root}/è‡ªå·±æ•™å¸«ã‚ã‚Šå­¦ç¿’'  # è‡ªå·±æ•™å¸«ã‚ã‚Šå­¦ç¿’ãƒ•ã‚©ãƒ«ãƒ€\n",
        "\n",
        "if os.path.exists(ssl_folder):\n",
        "    os.chdir(ssl_folder)\n",
        "    sys.path.insert(0, ssl_folder)\n",
        "    sys.path.insert(0, project_root)  # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚‚è¿½åŠ \n",
        "    print(f\"Working directory: {os.getcwd()}\")\n",
        "else:\n",
        "    print(f\"âš ï¸ {ssl_folder} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\")\n",
        "    print(\"Google Driveã«soturonãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã¦ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’è¨­å®š\n",
        "pickle_path = '/content/drive/MyDrive/soturon/data_lowF_noise.pickle'\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª\n",
        "import os\n",
        "if os.path.exists(pickle_path):\n",
        "    print(f\"âœ… Data file found: {pickle_path}\")\n",
        "else:\n",
        "    print(f\"âš ï¸ Data file not found at {pickle_path}\")\n",
        "    print(\"Google Driveã®soturonãƒ•ã‚©ãƒ«ãƒ€ã«data_lowF_noise.pickleã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨­å®šï¼ˆé‡è¦ï¼ï¼‰\n",
        "# Google Driveã«soturonãƒ•ã‚©ãƒ«ãƒ€ã‚’ãã®ã¾ã¾ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
        "project_root = '/content/drive/MyDrive/soturon'  # soturonãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ«ãƒ¼ãƒˆ\n",
        "ssl_folder = f'{project_root}/è‡ªå·±æ•™å¸«ã‚ã‚Šå­¦ç¿’'  # è‡ªå·±æ•™å¸«ã‚ã‚Šå­¦ç¿’ãƒ•ã‚©ãƒ«ãƒ€\n",
        "\n",
        "if os.path.exists(ssl_folder):\n",
        "    os.chdir(ssl_folder)\n",
        "    sys.path.insert(0, ssl_folder)\n",
        "    sys.path.insert(0, project_root)  # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚‚è¿½åŠ ï¼ˆeval.pyã‚„ãƒã‚¤ã‚ºãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç”¨ï¼‰\n",
        "    print(f\"Working directory: {os.getcwd()}\")\n",
        "else:\n",
        "    print(f\"âš ï¸ {ssl_folder} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\")\n",
        "    print(\"Google Driveã«soturonãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã¦ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚\")\n",
        "\n",
        "# å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«/ãƒ•ã‚©ãƒ«ãƒ€ã®å­˜åœ¨ç¢ºèª\n",
        "required_files = [\n",
        "    f'{ssl_folder}/task/__init__.py',\n",
        "    f'{ssl_folder}/task/dataset.py',\n",
        "    f'{ssl_folder}/task/model.py',\n",
        "    f'{ssl_folder}/task/train.py',\n",
        "    f'{project_root}/ãƒã‚¤ã‚ºã®ä»˜ä¸(å…±é€š)/__init__.py',\n",
        "    f'{project_root}/ãƒã‚¤ã‚ºã®ä»˜ä¸(å…±é€š)/add_noise.py',\n",
        "    f'{project_root}/ãƒã‚¤ã‚ºã®ä»˜ä¸(å…±é€š)/power_supply_noise.py',\n",
        "    f'{project_root}/ãƒã‚¤ã‚ºã®ä»˜ä¸(å…±é€š)/interference_noise.py',\n",
        "    f'{project_root}/ãƒã‚¤ã‚ºã®ä»˜ä¸(å…±é€š)/clock_leakage_noise.py',\n",
        "    f'{project_root}/eval.py',\n",
        "    f'{project_root}/data_lowF_noise.pickle'\n",
        "]\n",
        "\n",
        "missing_files = []\n",
        "for file in required_files:\n",
        "    if not os.path.exists(file):\n",
        "        # ãƒ‘ã‚¹ã‚’çŸ­ç¸®ã—ã¦è¡¨ç¤º\n",
        "        if file.startswith(ssl_folder):\n",
        "            missing_files.append(file.replace(ssl_folder + '/', 'è‡ªå·±æ•™å¸«ã‚ã‚Šå­¦ç¿’/'))\n",
        "        elif file.startswith(project_root):\n",
        "            missing_files.append(file.replace(project_root + '/', ''))\n",
        "\n",
        "if missing_files:\n",
        "    print(\"âš ï¸ ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«/ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“:\")\n",
        "    for file in missing_files:\n",
        "        print(f\"  - {file}\")\n",
        "    print(f\"\\nğŸ“ Google Driveã® {project_root} ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚\")\n",
        "    print(\"   ãƒ•ã‚©ãƒ«ãƒ€æ§‹é€ :\")\n",
        "    print(\"   soturon/\")\n",
        "    print(\"   â”œâ”€â”€ è‡ªå·±æ•™å¸«ã‚ã‚Šå­¦ç¿’/\")\n",
        "    print(\"   â”‚   â””â”€â”€ task/\")\n",
        "    print(\"   â”œâ”€â”€ ãƒã‚¤ã‚ºã®ä»˜ä¸(å…±é€š)/\")\n",
        "    print(\"   â”œâ”€â”€ eval.py\")\n",
        "    print(\"   â””â”€â”€ data_lowF_noise.pickle\")\n",
        "else:\n",
        "    print(\"âœ… ã™ã¹ã¦ã®å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸï¼\")\n",
        "\n",
        "# ãƒã‚¤ã‚ºãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’æ­£ã—ãç™»éŒ²ï¼ˆç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è§£æ±ºã™ã‚‹ãŸã‚ï¼‰\n",
        "print(\"\\nnoiseãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’sys.modulesã«ç™»éŒ²ä¸­...\")\n",
        "noise_folder_path = os.path.join(project_root, 'ãƒã‚¤ã‚ºã®ä»˜ä¸(å…±é€š)')\n",
        "\n",
        "# æ—¢å­˜ã®noiseãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å‰Šé™¤ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ï¼‰\n",
        "if 'noise' in sys.modules:\n",
        "    del sys.modules['noise']\n",
        "if 'noise.add_noise' in sys.modules:\n",
        "    del sys.modules['noise.add_noise']\n",
        "\n",
        "# __pycache__ã‚’ã‚¯ãƒªã‚¢ï¼ˆå¤ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤ï¼‰\n",
        "import shutil\n",
        "pycache_path = os.path.join(noise_folder_path, '__pycache__')\n",
        "if os.path.exists(pycache_path):\n",
        "    try:\n",
        "        shutil.rmtree(pycache_path)\n",
        "        print(f\"å¤ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤: {pycache_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®å‰Šé™¤ã«å¤±æ•—ï¼ˆç„¡è¦–ã—ã¾ã™ï¼‰: {e}\")\n",
        "\n",
        "# __init__.pyã®å†…å®¹ã‚’ç¢ºèªã—ã€å¿…è¦ã«å¿œã˜ã¦ä¿®æ­£\n",
        "init_path = os.path.join(noise_folder_path, '__init__.py')\n",
        "print(f\"  __init__.pyã®ãƒ‘ã‚¹: {init_path}\")\n",
        "\n",
        "# Google Colabä¸Šã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤ã„å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€æ­£ã—ã„å†…å®¹ã‚’æ›¸ãè¾¼ã‚€\n",
        "correct_init_content = '''\"\"\"\n",
        "æ¸¬å®šç³»ç”±æ¥ã®ãƒã‚¤ã‚ºã‚’ä»˜ä¸ã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«\n",
        "\"\"\"\n",
        "\n",
        "from .power_supply_noise import add_power_supply_noise\n",
        "from .interference_noise import add_interference_noise\n",
        "from .clock_leakage_noise import add_clock_leakage_noise\n",
        "from .add_noise import add_noise_to_interval\n",
        "\n",
        "__all__ = [\n",
        "    'add_power_supply_noise',\n",
        "    'add_interference_noise',\n",
        "    'add_clock_leakage_noise',\n",
        "    'add_noise_to_interval'\n",
        "]\n",
        "'''\n",
        "\n",
        "# __init__.pyã®å†…å®¹ã‚’ç¢ºèª\n",
        "try:\n",
        "    with open(init_path, 'r', encoding='utf-8') as f:\n",
        "        current_content = f.read()\n",
        "    \n",
        "    # å¤ã„å†…å®¹ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯æ›¸ãæ›ãˆã‚‹\n",
        "    if 'frequency_band_noise' in current_content or 'localized_spike_noise' in current_content:\n",
        "        print(\"  å¤ã„__init__.pyã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚æ­£ã—ã„å†…å®¹ã«æ›¸ãæ›ãˆã¾ã™...\")\n",
        "        with open(init_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(correct_init_content)\n",
        "        print(\"  âœ“ __init__.pyã‚’æ›´æ–°ã—ã¾ã—ãŸ\")\n",
        "    else:\n",
        "        print(\"  âœ“ __init__.pyã¯æ—¢ã«æ­£ã—ã„å†…å®¹ã§ã™\")\n",
        "except Exception as e:\n",
        "    print(f\"  âš  __init__.pyã®ç¢ºèªã«å¤±æ•—ã—ã¾ã—ãŸãŒã€ç¶šè¡Œã—ã¾ã™: {e}\")\n",
        "\n",
        "# ãƒã‚¤ã‚ºãƒ•ã‚©ãƒ«ãƒ€ã‚’sys.pathã«è¿½åŠ ï¼ˆç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è§£æ±ºã™ã‚‹ãŸã‚ï¼‰\n",
        "if noise_folder_path not in sys.path:\n",
        "    sys.path.insert(0, noise_folder_path)\n",
        "\n",
        "import importlib.util\n",
        "\n",
        "# noiseãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®__init__.pyã‚’ãƒ­ãƒ¼ãƒ‰\n",
        "init_spec = importlib.util.spec_from_file_location(\"noise\", init_path)\n",
        "init_module = importlib.util.module_from_spec(init_spec)\n",
        "sys.modules['noise'] = init_module\n",
        "# __file__ã¨__path__ã‚’è¨­å®šï¼ˆç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã®ãŸã‚ï¼‰\n",
        "init_module.__file__ = init_path\n",
        "init_module.__path__ = [noise_folder_path]\n",
        "init_spec.loader.exec_module(init_module)\n",
        "\n",
        "# add_noise.pyã‚’ãƒ­ãƒ¼ãƒ‰\n",
        "add_noise_path = os.path.join(noise_folder_path, 'add_noise.py')\n",
        "add_noise_spec = importlib.util.spec_from_file_location(\"noise.add_noise\", add_noise_path)\n",
        "add_noise_module = importlib.util.module_from_spec(add_noise_spec)\n",
        "sys.modules['noise.add_noise'] = add_noise_module\n",
        "add_noise_module.__file__ = add_noise_path\n",
        "add_noise_spec.loader.exec_module(add_noise_module)\n",
        "\n",
        "print(\"âœ“ noiseãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’sys.modulesã«ç™»éŒ²ã—ã¾ã—ãŸ\")\n",
        "print(f\"  åˆ©ç”¨å¯èƒ½ãªé–¢æ•°: {init_module.__all__}\")\n",
        "\n",
        "# add_noiseãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ç›´æ¥ç™»éŒ²ï¼ˆtask/dataset.pyãŒ`from add_noise import`ã‚’ä½¿ã†ãŸã‚ï¼‰\n",
        "sys.modules['add_noise'] = add_noise_module\n",
        "print(\"âœ“ add_noiseãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ç›´æ¥ç™»éŒ²ã—ã¾ã—ãŸ\")\n",
        "\n",
        "# ã‚¿ã‚¹ã‚¯4ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
        "try:\n",
        "    from task.dataset import Task4Dataset\n",
        "    from task.model import Task4BERT\n",
        "    from task.train import train_task4\n",
        "    import eval\n",
        "    print(\"âœ… ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«æˆåŠŸã—ã¾ã—ãŸï¼\")\n",
        "except ImportError as e:\n",
        "    print(f\"âŒ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}\")\n",
        "    print(\"   ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£ã—ãã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. å­¦ç¿’ã®å®Ÿè¡Œ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ãƒ‡ãƒã‚¤ã‚¹ã®ç¢ºèª\n",
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "if device == \"cuda\":\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’å‰Šé™¤ã—ã¦æœ€åˆã‹ã‚‰å­¦ç¿’ã™ã‚‹å ´åˆï¼ˆå¿…è¦ã«å¿œã˜ã¦å®Ÿè¡Œï¼‰\n",
        "import os\n",
        "checkpoint_path = \"/content/drive/MyDrive/soturon/è‡ªå·±æ•™å¸«ã‚ã‚Šå­¦ç¿’/task4_output/checkpoint.pth\"\n",
        "if os.path.exists(checkpoint_path):\n",
        "    print(\"æ—¢å­˜ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚å‰Šé™¤ã—ã¾ã™...\")\n",
        "    os.remove(checkpoint_path)\n",
        "    print(\"âœ“ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚æœ€åˆã‹ã‚‰å­¦ç¿’ã—ã¾ã™ã€‚\")\n",
        "else:\n",
        "    print(\"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã¯å­˜åœ¨ã—ã¾ã›ã‚“ã€‚æœ€åˆã‹ã‚‰å­¦ç¿’ã—ã¾ã™ã€‚\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å­¦ç¿’ã‚’å®Ÿè¡Œ\n",
        "# æœ€åˆã‹ã‚‰å­¦ç¿’ã™ã‚‹å ´åˆã¯ resume=False ã«å¤‰æ›´ã—ã¦ãã ã•ã„\n",
        "# ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å†é–‹ã™ã‚‹å ´åˆã¯ resume=True ã®ã¾ã¾ã«ã—ã¦ãã ã•ã„\n",
        "\n",
        "# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰\n",
        "from task.train import train_task4\n",
        "\n",
        "model, train_losses, val_losses, best_val_loss = train_task4(\n",
        "    pickle_path=pickle_path,\n",
        "    batch_size=16,  # é€Ÿåº¦å‘ä¸Šã®ãŸã‚8â†’16ã«å¤‰æ›´\n",
        "    num_epochs=10,  # ã‚¨ãƒãƒƒã‚¯æ•°ï¼ˆ10ã‚¨ãƒãƒƒã‚¯ã§ç´„1æ™‚é–“ï¼‰\n",
        "    lr=1e-3,  # 1e-4 â†’ 1e-3ã«å¤‰æ›´ï¼ˆæ­£å‰‡åŒ–é …ã®å­¦ç¿’ã‚’ä¿ƒé€²ï¼‰\n",
        "    val_ratio=0.2,\n",
        "    device=device,\n",
        "    out_dir=\"/content/drive/MyDrive/soturon/è‡ªå·±æ•™å¸«ã‚ã‚Šå­¦ç¿’/task4_output\",  # å‡ºåŠ›å…ˆã‚’Google Driveã«\n",
        "    resume=False,  # Falseã«å¤‰æ›´: æœ€åˆã‹ã‚‰å­¦ç¿’ / True: ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å†é–‹\n",
        "    lambda_reg=2.0,  # æ­£å‰‡åŒ–é …ã®é‡ã¿ã‚’å¢—ã‚„ã™ï¼ˆ0.5 â†’ 2.0ã€ãƒã‚¤ã‚ºæ¤œçŸ¥ã‚’é‡è¦–ï¼‰\n",
        "    num_intervals=30,\n",
        "    noise_type='power_supply',  # ãƒã‚¤ã‚ºã‚¿ã‚¤ãƒ—: 'power_supply', 'interference', 'clock_leakage'ï¼ˆuse_random_noise=Falseã®å ´åˆã®ã¿ä½¿ç”¨ï¼‰\n",
        "    use_random_noise=True,  # 3ç¨®é¡ã®ãƒã‚¤ã‚ºã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ä½¿ç”¨ï¼ˆæ¨å¥¨ï¼‰\n",
        "    noise_level=0.3,  # ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ï¼ˆ30%ï¼‰\n",
        "    margin=0.01,  # 0.2 â†’ 0.01ã«å¤‰æ›´ï¼ˆå­¦ç¿’ãŒé€²ã¿ã‚„ã™ãã™ã‚‹ï¼‰\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å­¦ç¿’æ›²ç·šã‚’å¯è¦–åŒ–ï¼ˆå¾©å…ƒæå¤±ã®ã¿ï¼‰\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=UserWarning, module='matplotlib')\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
        "\n",
        "# å¾©å…ƒæå¤±\n",
        "if len(train_recon_losses) > 0 and len(val_recon_losses) > 0:\n",
        "    ax.plot(train_recon_losses, label='Train Recon Loss', color='blue', linewidth=2)\n",
        "    ax.plot(val_recon_losses, label='Val Recon Loss', color='red', linewidth=2)\n",
        "    ax.set_xlabel('Epoch', fontsize=12)\n",
        "    ax.set_ylabel('Reconstruction Loss', fontsize=12)\n",
        "    ax.set_title('Reconstruction Loss', fontsize=14, fontweight='bold')\n",
        "    ax.legend(fontsize=11)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    save_path = \"/content/drive/MyDrive/soturon/è‡ªå·±æ•™å¸«ã‚ã‚Šå­¦ç¿’/task4_output/training_curves_recon.png\"\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    print(f\"å­¦ç¿’æ›²ç·šã‚’ '{save_path}' ã«ä¿å­˜ã—ã¾ã—ãŸ\")\n",
        "    \n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"å¾©å…ƒæå¤±ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å­¦ç¿’ãŒå®Œäº†ã—ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# è©•ä¾¡ã«å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
        "import os\n",
        "import sys\n",
        "import importlib\n",
        "\n",
        "# ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨­å®šï¼ˆé‡è¦ï¼ï¼‰\n",
        "project_root = '/content/drive/MyDrive/soturon'  # soturonãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ«ãƒ¼ãƒˆ\n",
        "project_path = f'{project_root}/è‡ªå·±æ•™å¸«ã‚ã‚Šå­¦ç¿’'  # è‡ªå·±æ•™å¸«ã‚ã‚Šå­¦ç¿’ãƒ•ã‚©ãƒ«ãƒ€\n",
        "if os.path.exists(project_path):\n",
        "    os.chdir(project_path)\n",
        "    sys.path.insert(0, project_path)\n",
        "    sys.path.insert(0, project_root)  # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚‚è¿½åŠ ï¼ˆeval.pyã‚„ãƒã‚¤ã‚ºãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç”¨ï¼‰\n",
        "    print(f\"Working directory: {os.getcwd()}\")\n",
        "else:\n",
        "    print(f\"âš ï¸ {project_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\")\n",
        "    print(\"Google Driveã«soturonãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã¦ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚\")\n",
        "\n",
        "# å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
        "from task.dataset import Task4Dataset\n",
        "from task.model import Task4BERT\n",
        "import torch\n",
        "import eval\n",
        "\n",
        "# evalãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å†èª­ã¿è¾¼ã¿ï¼ˆeval.pyã‚’å¤‰æ›´ã—ãŸå ´åˆï¼‰\n",
        "if 'eval' in sys.modules:\n",
        "    importlib.reload(sys.modules['eval'])\n",
        "    print(\"evalãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å†èª­ã¿è¾¼ã¿ã—ã¾ã—ãŸ\")\n",
        "\n",
        "# ãƒ‡ãƒã‚¤ã‚¹ã®è¨­å®šï¼ˆã¾ã è¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆï¼‰\n",
        "if 'device' not in globals():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ã®è¨­å®šï¼ˆã¾ã è¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆï¼‰\n",
        "if 'pickle_path' not in globals():\n",
        "    pickle_path = \"/content/drive/MyDrive/soturon/data_lowF_noise.pickle\"\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ï¼ˆã¾ã åˆæœŸåŒ–ã•ã‚Œã¦ã„ãªã„å ´åˆï¼‰\n",
        "if 'model' not in globals() or model is None:\n",
        "    seq_len = 3000\n",
        "    model = Task4BERT(\n",
        "        seq_len=seq_len,\n",
        "        d_model=64,\n",
        "        n_heads=2,\n",
        "        num_layers=2,\n",
        "        dim_feedforward=128,\n",
        "        dropout=0.1,\n",
        "    ).to(device)\n",
        "    print(\"ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. è©•ä¾¡ã®å®Ÿè¡Œ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ\n",
        "test_dataset = Task4Dataset(\n",
        "    pickle_path=pickle_path,\n",
        "    num_intervals=30,\n",
        "    noise_type='power_supply',  # å­¦ç¿’æ™‚ã¨åŒã˜ãƒã‚¤ã‚ºã‚¿ã‚¤ãƒ—ï¼ˆuse_random_noise=Falseã®å ´åˆã®ã¿ä½¿ç”¨ï¼‰\n",
        "    use_random_noise=True,  # å­¦ç¿’æ™‚ã¨åŒã˜è¨­å®š\n",
        "    noise_level=0.3,  # å­¦ç¿’æ™‚ã¨åŒã˜ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«\n",
        "    add_structured_noise_flag=True,  # å…¨ä½“çš„ãªæ§‹é€ åŒ–ãƒã‚¤ã‚ºã‚’ä»˜ä¸ï¼ˆå­¦ç¿’æ™‚ã¨åŒã˜ï¼‰\n",
        ")\n",
        "\n",
        "# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’ä½œæˆï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)  # é€Ÿåº¦å‘ä¸Šã®ãŸã‚8â†’16ã«å¤‰æ›´\n",
        "\n",
        "# æœ€è‰¯ã®ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿\n",
        "best_model_path = \"/content/drive/MyDrive/soturon/è‡ªå·±æ•™å¸«ã‚ã‚Šå­¦ç¿’/task4_output/best_val_model.pth\"\n",
        "model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
        "\n",
        "# è©•ä¾¡ã‚’å®Ÿè¡Œ\n",
        "results = eval.evaluate_model(\n",
        "    model=model,\n",
        "    dataloader=test_loader,\n",
        "    method='self_supervised',\n",
        "    device=device,\n",
        "    num_intervals=30,\n",
        ")\n",
        "\n",
        "# çµæœã‚’è¡¨ç¤º\n",
        "print(\"\\nè©•ä¾¡çµæœ:\")\n",
        "print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
        "print(f\"Precision: {results['precision']:.4f}\")\n",
        "print(f\"Recall: {results['recall']:.4f}\")\n",
        "print(f\"F1-score: {results['f1_score']:.4f}\")\n",
        "if 'loss' in results:\n",
        "    if results['loss'] == float('inf'):\n",
        "        print(f\"å¾©å…ƒæå¤±: è¨ˆç®—ä¸å¯ï¼ˆãƒã‚¤ã‚ºæ¤œçŸ¥ãŒæ­£ã—ã„ã‚µãƒ³ãƒ—ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ï¼‰\")\n",
        "    else:\n",
        "        print(f\"å¾©å…ƒæå¤±ï¼ˆlossã‚­ãƒ¼ï¼‰: {results['loss']:.6f} - æœ€ã‚‚é‡è¦ãªæŒ‡æ¨™\")\n",
        "if 'reconstruction_loss' in results and results['reconstruction_loss'] is not None:\n",
        "    print(f\"å¾©å…ƒæå¤±: {results['reconstruction_loss']:.6f}\")\n",
        "if 'reconstruction_accuracy' in results and results['reconstruction_accuracy'] is not None:\n",
        "    print(f\"å¾©å…ƒç²¾åº¦: {results['reconstruction_accuracy']:.2f}%\")\n",
        "if 'roc_auc' in results:\n",
        "    print(f\"ROC-AUC: {results['roc_auc']:.4f}\")\n",
        "if 'attention_diff' in results:\n",
        "    print(f\"ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚¦ã‚§ã‚¤ãƒˆã®å·®: {results['attention_diff']:.4f}\")\n",
        "    print(f\"  (æ­£å¸¸åŒºé–“ - ãƒã‚¤ã‚ºåŒºé–“)\")\n",
        "if 'best_threshold' in results:\n",
        "    print(f\"æœ€é©é–¾å€¤: {results['best_threshold']:.6f}\")\n",
        "if 'noise_attention_mean' in results:\n",
        "    print(f\"ãƒã‚¤ã‚ºåŒºé–“ã®å¹³å‡ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³: {results['noise_attention_mean']:.6f}\")\n",
        "if 'normal_attention_mean' in results:\n",
        "    print(f\"æ­£å¸¸åŒºé–“ã®å¹³å‡ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³: {results['normal_attention_mean']:.6f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# æ··åŒè¡Œåˆ—ã‚’å¯è¦–åŒ–\n",
        "eval.plot_confusion_matrix(\n",
        "    results['confusion_matrix'],\n",
        "    title='ã‚¿ã‚¹ã‚¯4: æ··åŒè¡Œåˆ—',\n",
        "    save_path=\"/content/drive/MyDrive/soturon/è‡ªå·±æ•™å¸«ã‚ã‚Šå­¦ç¿’/task4_output/confusion_matrix.png\"\n",
        ")\n",
        "print(\"æ··åŒè¡Œåˆ—ã‚’ä¿å­˜ã—ã¾ã—ãŸ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚¦ã‚§ã‚¤ãƒˆã®åˆ†å¸ƒã‚’å¯è¦–åŒ–\n",
        "if 'attention_weights' in results:\n",
        "    eval.plot_attention_distribution(\n",
        "        results['attention_weights'],\n",
        "        results['labels'],\n",
        "        num_intervals=30,\n",
        "        save_path=\"/content/drive/MyDrive/soturon/è‡ªå·±æ•™å¸«ã‚ã‚Šå­¦ç¿’/task4_output/attention_distribution.png\"\n",
        "    )\n",
        "    print(\"ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚¦ã‚§ã‚¤ãƒˆã®åˆ†å¸ƒã‚’ä¿å­˜ã—ã¾ã—ãŸ\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
