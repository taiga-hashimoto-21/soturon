{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™\n",
        "\n",
        "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ã€æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã«ãƒã‚¤ã‚ºã‚’ä»˜ä¸ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æº–å‚™ã—ã¾ã™ã€‚\n",
        "\n",
        "## æ‰‹é †\n",
        "\n",
        "1. Google Driveã‚’ãƒã‚¦ãƒ³ãƒˆ\n",
        "2. å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
        "3. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™ã‚’å®Ÿè¡Œ\n",
        "4. çµæœã‚’Google Driveã«ä¿å­˜\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Google Driveã‚’ãƒã‚¦ãƒ³ãƒˆ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Google Driveã«soturonãƒ•ã‚©ãƒ«ãƒ€ã‚’ãã®ã¾ã¾ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
        "project_root = '/content/drive/MyDrive/soturon'  # soturonãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ«ãƒ¼ãƒˆ\n",
        "baseline_folder = f'{project_root}/ç•³ã¿è¾¼ã¿'  # ç•³ã¿è¾¼ã¿ãƒ•ã‚©ãƒ«ãƒ€\n",
        "\n",
        "if os.path.exists(baseline_folder):\n",
        "    os.chdir(baseline_folder)\n",
        "    sys.path.insert(0, baseline_folder)\n",
        "    sys.path.insert(0, project_root)  # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚‚è¿½åŠ \n",
        "    print(f\"Working directory: {os.getcwd()}\")\n",
        "else:\n",
        "    print(f\"âš ï¸ {baseline_folder} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\")\n",
        "    print(\"Google Driveã«soturonãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã¦ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª\n",
        "required_files = [\n",
        "    f'{project_root}/data_lowF_noise_time.pickle',  # æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿\n",
        "    f'{project_root}/ãƒã‚¤ã‚ºã®ä»˜ä¸(å…±é€š)/timeseries_noise.py',\n",
        "    f'{baseline_folder}/dataset_timeseries.py',\n",
        "]\n",
        "\n",
        "missing_files = []\n",
        "for file in required_files:\n",
        "    if not os.path.exists(file):\n",
        "        if file.startswith(baseline_folder):\n",
        "            missing_files.append(file.replace(baseline_folder + '/', 'ç•³ã¿è¾¼ã¿/'))\n",
        "        elif file.startswith(project_root):\n",
        "            missing_files.append(file.replace(project_root + '/', ''))\n",
        "\n",
        "if missing_files:\n",
        "    print(\"âš ï¸ ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“:\")\n",
        "    for file in missing_files:\n",
        "        print(f\"  - {file}\")\n",
        "    print(f\"\\nğŸ“ Google Driveã® {project_root} ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚\")\n",
        "else:\n",
        "    print(\"âœ… ã™ã¹ã¦ã®å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸï¼\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™ã®å®Ÿè¡Œ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ\n",
        "# ã‚¹ã‚¯ãƒªãƒ—ãƒˆå†…ã§data_lowF_noise_time.pickleã‚’èª­ã¿è¾¼ã‚“ã§å‡¦ç†ã—ã¾ã™\n",
        "\n",
        "# ã¾ãšã€ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’ç¢ºèª\n",
        "data_path = f'{project_root}/data_lowF_noise_time.pickle'\n",
        "if os.path.exists(data_path):\n",
        "    print(f\"âœ… æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ: {data_path}\")\n",
        "    \n",
        "    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦å®Ÿè¡Œ\n",
        "    # ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ç›´æ¥å®Ÿè¡Œã™ã‚‹æ–¹æ³•\n",
        "    import subprocess\n",
        "    import sys\n",
        "    \n",
        "    # ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒ‘ã‚¹\n",
        "    script_path = f'{baseline_folder}/dataset_timeseries.py'\n",
        "    \n",
        "    if os.path.exists(script_path):\n",
        "        print(f\"\\nãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™ã‚’å®Ÿè¡Œä¸­...\")\n",
        "        print(\"=\" * 60)\n",
        "        \n",
        "        # ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ\n",
        "        result = subprocess.run(\n",
        "            [sys.executable, script_path],\n",
        "            cwd=baseline_folder,\n",
        "            capture_output=True,\n",
        "            text=True\n",
        "        )\n",
        "        \n",
        "        print(result.stdout)\n",
        "        if result.stderr:\n",
        "            print(\"ã‚¨ãƒ©ãƒ¼:\")\n",
        "            print(result.stderr)\n",
        "        \n",
        "        print(\"=\" * 60)\n",
        "    else:\n",
        "        print(f\"âš ï¸ ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {script_path}\")\n",
        "else:\n",
        "    print(f\"âš ï¸ æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {data_path}\")\n",
        "    print(\"å…ˆã« convert_psd_to_timeseries.ipynb ã‚’å®Ÿè¡Œã—ã¦ã€æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. çµæœã®ç¢ºèª\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã‚“ã§ç¢ºèª\n",
        "dataset_path = f'{baseline_folder}/baseline_dataset_timeseries.pickle'\n",
        "\n",
        "if os.path.exists(dataset_path):\n",
        "    print(f\"âœ… ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ: {dataset_path}\")\n",
        "    \n",
        "    with open(dataset_path, 'rb') as f:\n",
        "        dataset = pickle.load(f)\n",
        "    \n",
        "    train_data = dataset['train']['data']\n",
        "    train_labels = dataset['train']['labels']\n",
        "    val_data = dataset['val']['data']\n",
        "    val_labels = dataset['val']['labels']\n",
        "    test_data = dataset['test']['data']\n",
        "    test_labels = dataset['test']['labels']\n",
        "    config = dataset['config']\n",
        "    \n",
        "    print(f\"\\nãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æƒ…å ±:\")\n",
        "    print(f\"  è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(train_data):,}ã‚µãƒ³ãƒ—ãƒ«\")\n",
        "    print(f\"  æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿: {len(val_data):,}ã‚µãƒ³ãƒ—ãƒ«\")\n",
        "    print(f\"  ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(test_data):,}ã‚µãƒ³ãƒ—ãƒ«\")\n",
        "    print(f\"  ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {train_data.shape}\")\n",
        "    print(f\"\\nè¨­å®š:\")\n",
        "    print(f\"  åŒºé–“æ•°: {config['num_intervals']}\")\n",
        "    print(f\"  ãƒã‚¤ã‚ºã‚¿ã‚¤ãƒ—: {config['noise_type']}\")\n",
        "    print(f\"  ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«: {config['noise_level']}\")\n",
        "    print(f\"  ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—: {config.get('data_type', 'unknown')}\")\n",
        "    \n",
        "    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å¯è¦–åŒ–\n",
        "    sample_idx = 0\n",
        "    sample = train_data[sample_idx].numpy()\n",
        "    label = train_labels[sample_idx].item()\n",
        "    \n",
        "    points_per_interval = len(sample) // config['num_intervals']\n",
        "    noise_start = label * points_per_interval\n",
        "    noise_end = noise_start + points_per_interval\n",
        "    \n",
        "    plt.figure(figsize=(14, 5))\n",
        "    plt.plot(sample, linewidth=1, alpha=0.7, label='ãƒã‚¤ã‚ºä»˜ä¸å¾Œ')\n",
        "    plt.axvspan(noise_start, noise_end, alpha=0.2, color='red', label=f'ãƒã‚¤ã‚ºåŒºé–“ {label}')\n",
        "    plt.title(f'æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚µãƒ³ãƒ—ãƒ« {sample_idx}ã€ãƒ©ãƒ™ãƒ«: {label}ï¼‰')\n",
        "    plt.xlabel('æ™‚é–“ãƒã‚¤ãƒ³ãƒˆ')\n",
        "    plt.ylabel('æ­£è¦åŒ–å¾Œã®å€¤')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\nã‚µãƒ³ãƒ—ãƒ« {sample_idx} ã®çµ±è¨ˆæƒ…å ±:\")\n",
        "    print(f\"  æœ€å°å€¤: {sample.min():.6f}\")\n",
        "    print(f\"  æœ€å¤§å€¤: {sample.max():.6f}\")\n",
        "    print(f\"  å¹³å‡å€¤: {sample.mean():.6f}\")\n",
        "    print(f\"  æ¨™æº–åå·®: {sample.std():.6f}\")\n",
        "    print(f\"  ãƒã‚¤ã‚ºåŒºé–“: {noise_start}-{noise_end}\")\n",
        "    \n",
        "else:\n",
        "    print(f\"âš ï¸ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {dataset_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
