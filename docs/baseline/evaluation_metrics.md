# ノイズ検出の評価指標

## 1. 愚直な手法（30クラス分類）の評価

### 出力形式
- **予測**: どの区間（1~30）にノイズがあるか
- **正解**: 実際にノイズが付与された区間番号

### 評価指標

#### 1.1 区間レベルの精度（Interval-level Accuracy）
```
Accuracy = 正しく予測したサンプル数 / 全サンプル数
```
- **例**: 1000サンプル中、850サンプルで正しい区間を予測 → Accuracy = 85%

#### 1.2 混同行列（Confusion Matrix）
- どの区間をどの区間と間違えやすいかを可視化
- 30×30の行列

#### 1.3 Precision, Recall, F1-score（区間ごと）
- 各区間（1~30）について計算
- マクロ平均、マイクロ平均を計算

---

## 2. 自己教師あり学習（アテンションウェイト）の評価

### 出力形式
- **予測**: 各ポイント（または区間）に対するアテンションウェイト（連続値）
- **正解**: ノイズが付与された区間のインデックス

### 評価指標

#### 2.1 アテンションウェイトの平均値比較
```
ノイズ区間の平均アテンションウェイト < 正常区間の平均アテンションウェイト
```
- 理想: ノイズ区間のアテンションウェイトが低い
- **指標**: ノイズ区間と正常区間のアテンションウェイトの差

#### 2.2 閾値ベースの精度（Threshold-based Accuracy）
1. アテンションウェイトを区間ごとに平均化（30区間）
2. 閾値を設定（例: 全区間の中央値、または下位X%）
3. 閾値以下の区間を「ノイズあり」と判定
4. 正解区間と一致するかで精度を計算

```
予測ノイズ区間 = {区間i | アテンションウェイト[i] < 閾値}
正解ノイズ区間 = {実際にノイズが付与された区間}

Accuracy = |予測ノイズ区間 ∩ 正解ノイズ区間| / |正解ノイズ区間|
```

#### 2.3 ROC-AUC（Receiver Operating Characteristic - Area Under Curve）
- アテンションウェイトを連続値として扱い、閾値を変えながら評価
- ノイズ区間を正しく検出できる能力を評価

#### 2.4 Precision, Recall, F1-score（閾値ベース）
- 閾値を設定した場合のPrecision, Recall, F1-score
- 閾値は最適化可能（F1-scoreが最大になる閾値を選択）

#### 2.5 アテンションウェイトの分布
- ノイズ区間と正常区間のアテンションウェイトの分布を可視化
- Kolmogorov-Smirnov検定などで統計的に比較

---

## 3. 比較方法

### 3.1 直接比較可能な指標

#### **Accuracy（精度）**
- **愚直な手法**: 区間レベルのAccuracy（%）
- **自己教師あり学習**: 閾値ベースのAccuracy（%）
- **比較**: どちらが高いか

#### **F1-score**
- **愚直な手法**: マクロ平均F1-score
- **自己教師あり学習**: 閾値最適化後のF1-score
- **比較**: どちらが高いか

### 3.2 追加の評価

#### **アテンションウェイトの特性**
- 自己教師あり学習では、アテンションウェイトが「ノイズの存在確率」として解釈可能
- 連続値なので、より細かい分析が可能

#### **可視化**
- アテンションウェイトのヒートマップ
- ノイズ区間でのアテンションウェイトの分布

---

## 4. 推奨される評価フロー

### ステップ1: 愚直な手法の評価
1. 30クラス分類モデルを学習
2. テストデータで予測
3. **Accuracy**, **混同行列**, **F1-score**を計算

### ステップ2: 自己教師あり学習の評価
1. Transformerモデルを学習（アテンションウェイトを取得）
2. テストデータでアテンションウェイトを取得
3. 区間ごとにアテンションウェイトを平均化
4. **閾値を最適化**（F1-scoreが最大になる閾値を選択）
5. **Accuracy**, **F1-score**, **ROC-AUC**を計算
6. アテンションウェイトの分布を可視化

### ステップ3: 比較
1. **Accuracy**: 愚直な手法 vs 自己教師あり学習
2. **F1-score**: 愚直な手法 vs 自己教師あり学習
3. **追加の利点**: 自己教師あり学習では連続値なので、より柔軟な分析が可能

---

## 5. 実装例

### 愚直な手法の評価
```python
# 予測: [15, 12, 18, ...] (30クラス分類の結果)
# 正解: [15, 12, 18, ...]
accuracy = (predictions == labels).mean()
```

### 自己教師あり学習の評価
```python
# アテンションウェイト: shape = (batch_size, num_intervals)
# 例: attention_weights[i] = [0.05, 0.03, ..., 0.02, ...] (30区間)

# 1. 区間ごとに平均化
interval_attention = attention_weights.mean(dim=1)  # (batch_size, 30)

# 2. 閾値を最適化
thresholds = np.linspace(0, 1, 100)
best_threshold = optimize_threshold(interval_attention, labels, thresholds)

# 3. 予測
predictions = (interval_attention < best_threshold).argmax(dim=1)

# 4. 評価
accuracy = (predictions == labels).mean()
f1_score = calculate_f1_score(predictions, labels)
roc_auc = calculate_roc_auc(interval_attention, labels)
```

---

## 6. まとめ

### 比較すべき指標
1. **Accuracy（精度）**: 最も直感的で分かりやすい
2. **F1-score**: PrecisionとRecallのバランスを評価
3. **ROC-AUC**: 自己教師あり学習の連続値の特性を活かした評価

### 自己教師あり学習の利点
- 連続値なので、閾値を調整可能
- アテンションウェイトが「ノイズの存在確率」として解釈可能
- より柔軟な分析が可能

### 発表時の流れ
1. 愚直な手法の結果: Accuracy = X%
2. 自己教師あり学習の結果: Accuracy = Y% (Y > X)
3. 追加の分析: アテンションウェイトの分布、ROC-AUCなど
4. 結論: 自己教師あり学習の方が優れている


