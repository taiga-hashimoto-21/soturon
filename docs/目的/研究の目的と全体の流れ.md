# 研究の目的と全体の流れ

## 📌 研究の目的

**主目的**: PSD（パワースペクトル密度）データからノイズが載っている区間を検出する

**データ**: 野中さんが作成したPSDデータ（3万2000件）

**ゴール**: 
1. **第1目標**: ノイズ検出ができるようになること
2. **第2目標（できれば）**: ノイズを検出して排除したデータで解析した方が良い結果になることを示す

---

## 🔄 研究の全体の流れ

### 1. データ準備

- **元データ**: `data_lowF_noise.pickle`（PSD理論値データ、32000サンプル、各3000ポイント）
- **ノイズの付与**: 
  - データを30区間（または10区間）に分割
  - ランダムに1つの区間にノイズを付与
  - 3種類のノイズパターンを使用:
    1. **周波数帯域集中ノイズ** (`clock_leakage_noise.py`)
    2. **局所スパイクノイズ** (`interference_noise.py`)
    3. **振幅依存ノイズ** (`power_supply_noise.py`)
- **ラベル**: ノイズが付与された区間番号（0-29または0-9）

### 2. ベースライン手法（畳み込みモデル）

#### 2.1 アプローチ
- **モデル**: CNN（ResNet風の1D CNN）
- **タスク**: 30クラス分類（どの区間にノイズがあるかを予測）
- **学習方法**: 教師あり学習（ラベルを使用）

#### 2.2 評価指標
- **Accuracy**: 区間レベルの精度（%）
- **F1-score**: マクロ平均F1-score
- **混同行列**: 30×30の行列

#### 2.3 実行手順
1. データセット準備: `畳み込み/dataset.py`
2. 学習: `畳み込み/train.py` または `畳み込み/train_colab.ipynb`
3. 評価: `eval.py`

詳細は `docs/baseline/Colab実行手順.md` を参照

### 3. 自己教師あり学習手法（Transformer）

#### 3.1 アプローチ
- **モデル**: Transformerベースのモデル（アテンション機構を使用）
- **タスク**: 自己教師あり学習タスク（マスク予測、コントラスト学習など）
- **学習方法**: ラベルなしで学習（評価時のみラベルを使用）

#### 3.2 特徴
- **アテンションウェイト**: ノイズ区間のアテンションウェイトを制御
- **損失関数**: 
  - 自己教師あり学習タスクの損失
  - 正則化項: ノイズ区間のアテンションウェイトを下げる項

#### 3.3 評価指標
- **閾値ベースのAccuracy**: ベースラインと直接比較可能
- **F1-score**: 閾値最適化後のF1-score
- **ROC-AUC**: 自己教師あり学習の連続値の特性を活かした評価
- **アテンションウェイトの可視化**: ノイズ区間の識別状況を確認

#### 3.4 実行手順
1. データセット準備: `自己教師あり学習/prepare_dataset.py`
2. 学習: `自己教師あり学習/task/train.py` または `自己教師あり学習/train_colab.ipynb`
3. 評価: `eval.py`

詳細は `docs/ssl/Colab実行手順.md` を参照

### 4. 比較と評価

#### 4.1 比較方法
- **同じデータセット**: ベースラインと自己教師あり学習で同じデータを使用
- **同じノイズパターン**: 3種類のノイズパターンすべてで評価
- **同じ評価指標**: Accuracy, F1-scoreで直接比較

#### 4.2 評価フロー
1. **ベースライン手法の評価**
   - 30クラス分類のAccuracy: X%
   - F1-score: Y%
   - 損失曲線のグラフ

2. **自己教師あり学習の評価**
   - 閾値ベースのAccuracy: Z% (Z > X)
   - F1-score: W% (W > Y)
   - ROC-AUC: V
   - アテンションウェイトの可視化

3. **比較と考察**
   - 自己教師あり学習の方が精度が高い
   - アテンションウェイトがノイズ区間を正しく識別している
   - 連続値なので、より柔軟な分析が可能

詳細は `docs/baseline/evaluation_metrics.md` を参照

---

## 🎯 研究の意義

### なぜ自己教師あり学習か？

1. **ラベルなしで学習可能**: 活性化エネルギーのデータは使えないため、入力データだけで学習する必要がある
2. **アテンションウェイトの活用**: ノイズ区間のアテンションウェイトを制御することで、より柔軟な分析が可能
3. **連続値での評価**: 分類ではなく連続値なので、閾値を調整可能でより細かい分析が可能

### 期待される成果

- **精度向上**: 自己教師あり学習の方がベースラインより高い精度を達成
- **解釈可能性**: アテンションウェイトによってノイズ区間を可視化・解釈可能
- **実用性**: ノイズ検出後のデータでより良い解析結果が得られることを示す

---

## 📚 関連ドキュメント

### ベースライン関連
- `docs/baseline/Colab実行手順.md`: ベースライン手法の実行手順
- `docs/baseline/evaluation_metrics.md`: 評価指標の詳細

### 自己教師あり学習関連
- `docs/ssl/Colab実行手順.md`: 自己教師あり学習の実行手順
- `docs/ssl/学習内容まとめ.md`: 必要な技術・概念のまとめ
- `docs/ssl/task_design.md`: タスク設計の詳細
- `docs/ssl/migration.md`: ベースラインからの移行方針
- `docs/ssl/BERTとCLSトークンの説明.md`: Transformerの基礎知識

### コード
- `畳み込み/`: ベースライン手法の実装
- `自己教師あり学習/`: 自己教師あり学習の実装
- `ノイズの付与(共通)/`: ノイズ生成モジュール
- `eval.py`: 評価スクリプト

---

## 🔍 次のステップ

1. ✅ **データ準備**（完了）
2. ✅ **ベースライン手法の実装**（完了）
3. ⏳ **自己教師あり学習タスクの設計**
4. ⏳ **Transformerモデルの実装**
5. ⏳ **損失関数の実装**（正則化項を含む）
6. ⏳ **評価関数の実装**（既存の評価関数を流用）
7. ⏳ **実験と比較**
8. ⏳ **結果の可視化と分析**

---

## 📝 注意点

- **データの一貫性**: ベースラインと自己教師あり学習で同じデータセットを使用
- **評価の公平性**: 同じ評価指標、同じテストデータで評価
- **再現性**: 同じランダムシードを使用して再現性を保証
- **ノイズパターンの統一**: 3種類のノイズパターンすべてで評価

